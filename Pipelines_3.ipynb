{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipelines 3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOM0EZq/QSsfZK6zS1Ktfsv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Pipelines/blob/main/Pipelines_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipelines help you prevent data leakage in your test harness by ensuring that data preparation like standardization is constrained to each fold of your cross validation procedure."
      ],
      "metadata": {
        "id": "yHqNtkqX9fd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipelines for Data preparation and modeling constrained to each fold of the cross validation procedure**"
      ],
      "metadata": {
        "id": "RchbB5mbAAxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The example below demonstrates the pipeline defined with four steps:\n",
        "\n",
        "Feature Extraction with Principal Component Analysis (3 features)\n",
        "Feature Extraction with Statistical Selection (6 features)\n",
        "Feature Union\n",
        "Learn a Logistic Regression Model\n",
        "The pipeline is then evaluated using 10-fold cross validation."
      ],
      "metadata": {
        "id": "Bjqqr9TG9_Mw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IesA7Avl9UtN"
      },
      "outputs": [],
      "source": [
        "# Create a pipeline that standardizes the data then creates a model\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "# load data\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(url, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "# create pipeline\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
        "model = Pipeline(estimators)\n",
        "# evaluate pipeline\n",
        "seed = 7\n",
        "kfold = KFold(n_splits=10)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipelines for Feature extraction and feature union constrained to each fold of the cross validation procedure**"
      ],
      "metadata": {
        "id": "8ZSgrfI_AHty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline that extracts features from the data then creates a model\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "# load data\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(url, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "# create feature union\n",
        "features = []\n",
        "features.append(('pca', PCA(n_components=3)))\n",
        "features.append(('select_best', SelectKBest(k=6)))\n",
        "feature_union = FeatureUnion(features)\n",
        "# create pipeline\n",
        "estimators = []\n",
        "estimators.append(('feature_union', feature_union))\n",
        "#note max iterations **\n",
        "estimators.append(('logistic', LogisticRegression(dual=False, max_iter=8000 )))\n",
        "model = Pipeline(estimators)\n",
        "# evaluate pipeline\n",
        "seed = 7\n",
        "kfold = KFold(n_splits=10)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "metadata": {
        "id": "tvBg1ETw-Ezn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}