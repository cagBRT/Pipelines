{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 PipeLines .ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPS1y0krZrJbkq7hTPAhhEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Pipelines/blob/main/2_PipeLines_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipelines**"
      ],
      "metadata": {
        "id": "Ev0WX2jA-sk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of the pipeline is to assemble **several steps that can be cross-validated together** while setting different parameters."
      ],
      "metadata": {
        "id": "v-F_J9vn-p-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pipeline can be used to chain multiple estimators into one. <br>\n",
        "This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification.<br>\n",
        "\n",
        "Pipeline serves multiple purposes here:<br>\n",
        "\n",
        "- Convenience and encapsulation\n",
        "You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
        "\n",
        "- Joint parameter selection\n",
        "You can grid search over parameters of all estimators in the pipeline at once.\n",
        "\n",
        "- Safety\n",
        "Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
        "\n",
        "**All estimators in a pipeline, except the last one, must be transformers**(i.e. must have a transform method). <br>\n",
        "The last estimator may be any type (transformer, classifier, etc.).\n",
        "\n",
        "[Pipeline User Guide](https://scikit-learn.org/stable/modules/compose.html#pipeline)\n"
      ],
      "metadata": {
        "id": "PFG_BJrJ-5LO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pipeline is built using a list of (key, value) pairs, where <br>\n",
        "- the key is a string containing the name you want to give this step and <br>\n",
        "- value is an estimator object:"
      ],
      "metadata": {
        "id": "wz46NaDz_fbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "Nug0eOnx_qjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pipeline does Principal Component Analysis then uses a Supprt Vector Machine Model"
      ],
      "metadata": {
        "id": "HzqDj__eAFdY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnBnQzQb-e_B"
      },
      "outputs": [],
      "source": [
        "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
        "pipe = Pipeline(estimators)\n",
        "pipe"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The utility function make_pipeline is a shorthand for constructing pipelines;<br>\n",
        "\n",
        "it takes a variable number of estimators and returns a pipeline, filling in the names automatically:"
      ],
      "metadata": {
        "id": "tG-YvujOAPeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the make_pipeline library"
      ],
      "metadata": {
        "id": "U4qPojXeAeNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import Binarizer"
      ],
      "metadata": {
        "id": "KlGOVPgWAPqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pipeline makes the binarizer then inputs the data to the Naive Bayes model"
      ],
      "metadata": {
        "id": "RnR6-Q8NAkKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binarize data (set feature values to 0 or 1) according to a threshold."
      ],
      "metadata": {
        "id": "n_QAGpj7BC0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_pipeline(Binarizer(), MultinomialNB())"
      ],
      "metadata": {
        "id": "736wA96OAc8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of [Binarize](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html)"
      ],
      "metadata": {
        "id": "feViA2J5BGx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "X = [[ 1., -1.,  2.],\n",
        "     [ 2.,  0.,  0.],\n",
        "     [ 0.,  1., -1.]]\n",
        "transformer = Binarizer().fit(X)\n",
        "transformer\n",
        "\n",
        "transformer.transform(X)"
      ],
      "metadata": {
        "id": "YSJCE12MBI0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To access steps in the pipeline**"
      ],
      "metadata": {
        "id": "JzEBQPRxBk7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
        "pipe = Pipeline(estimators)\n",
        "print(\"Pipe\",pipe)\n",
        "print(\"Pipe steps\",pipe.steps[0], pipe.steps[1])\n",
        "print(\"Pipe[0]=\",pipe[0])\n",
        "print(\"Naming by function:\",pipe['reduce_dim'])"
      ],
      "metadata": {
        "id": "EKdJOFJ_BlHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nested Parameters**<br>\n",
        "Use estimator_parameters syntax to access the estimator parameters"
      ],
      "metadata": {
        "id": "bMtdRFenGHUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set the 'C' parameter for the SVM\n",
        "pipe.set_params(clf__C=10)"
      ],
      "metadata": {
        "id": "HgZi27JoGYWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting parameters for Grid Searches**"
      ],
      "metadata": {
        "id": "UJsyLV8hGmvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the grid search will try 2,5,10 number of dimensions for the PCA and 0.1,10,100 for the 'C' parameter for the SVM"
      ],
      "metadata": {
        "id": "37RFcqumGyJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = dict(reduce_dim__n_components=[2, 5, 10],\n",
        "                  clf__C=[0.1, 10, 100])\n",
        "grid_search = GridSearchCV(pipe, param_grid=param_grid)"
      ],
      "metadata": {
        "id": "t3DeSFNlGrHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting the features of the pipeline**"
      ],
      "metadata": {
        "id": "VBCaglHEFz0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectKBest"
      ],
      "metadata": {
        "id": "xqhIt7fDF4aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "param_grid = dict(reduce_dim=['passthrough', PCA(5), PCA(10)],\n",
        "                  clf=[SVC(), LogisticRegression()],\n",
        "                  clf__C=[0.1, 10, 100])\n",
        "grid_search = GridSearchCV(pipe, param_grid=param_grid)\n",
        "iris = load_iris()\n",
        "pipe = Pipeline(steps=[\n",
        "   ('select', SelectKBest(k=2)),\n",
        "   ('clf', LogisticRegression())])\n",
        "pipe.fit(iris.data, iris.target)\n",
        "\n",
        "pipe[:-1].get_feature_names_out()"
      ],
      "metadata": {
        "id": "OMf580CMF0DX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}